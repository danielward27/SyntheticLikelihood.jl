<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Samplers · SyntheticLikelihood.jl</title><link rel="canonical" href="https://danielward27.github.io/SyntheticLikelihood.jl/samplers/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">SyntheticLikelihood.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../examples/ricker/">Example</a></li><li><a class="tocitem" href="../local_regression/">Local regression</a></li><li class="is-active"><a class="tocitem" href>Samplers</a><ul class="internal"><li><a class="tocitem" href="#Implementation-details"><span>Implementation details</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Samplers</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Samplers</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/danielward27/SyntheticLikelihood.jl/blob/master/docs/src/samplers.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Samplers"><a class="docs-heading-anchor" href="#Samplers">Samplers</a><a id="Samplers-1"></a><a class="docs-heading-anchor-permalink" href="#Samplers" title="Permalink"></a></h1><p>To sample from a distribution, first a sampler object should be created. The currently available samplers are shown below:</p><article class="docstring"><header><a class="docstring-binding" id="SyntheticLikelihood.ULA" href="#SyntheticLikelihood.ULA"><code>SyntheticLikelihood.ULA</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Sampler for unadjusted langevin algorithm. Uses a discrete time Euler approximation of the langevin diffusion, given by the update θ := θ - η/2 * ∇ + ξ, where ξ is given by N(0, ηI).</p><ul><li><code>step_size</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/danielward27/SyntheticLikelihood.jl/blob/23cf97b906e407dda2f21d957935669d4f1d4572/src/samplers.jl#L5-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SyntheticLikelihood.RiemannianULA" href="#SyntheticLikelihood.RiemannianULA"><code>SyntheticLikelihood.RiemannianULA</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Sampler object for Riemannian ULA. Uses the update: θ := θ - ϵ²H⁻¹*∇ - ϵ√H⁻¹ z, where z ∼ N(0, I).</p><ul><li><code>step_size</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/danielward27/SyntheticLikelihood.jl/blob/23cf97b906e407dda2f21d957935669d4f1d4572/src/samplers.jl#L50-L55">source</a></section></article><p>The sampler object defines the hyperparameters of the sampler, and a function <code>obj_grad_hess</code>, which takes <code>θ</code> and returns a <code>ObjGradHess</code> object, with fields <code>objective</code>, <code>gradient</code> and <code>hessian</code>. The gradient and hessian defualt to <code>nothing</code> if not required. This approach seems a bit convoluted (compared to e.g. seperately passing objective, gradient and Hessian functions), but it facilitates reusing calculations shared between calculating the objective, gradient and hessian, if desired. The aim should be to explore around the minima of the function, so the objective could be the negative log-posterior, for example.</p><p>The sampler object can then passed to <code>run_sampler!</code>, to sample from the distribution:</p><article class="docstring"><header><a class="docstring-binding" id="SyntheticLikelihood.run_sampler!" href="#SyntheticLikelihood.run_sampler!"><code>SyntheticLikelihood.run_sampler!</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Run the sampling algorithm. Data to collect at each iteration is specified by <code>collect_data</code>, and should be a subset of <code>[:θ, :objective, :gradient, :hessian, :counter]</code>.</p><pre><code class="language-julia">run_sampler!(sampler, local_approximation; init_θ, n_steps, collect_data)
</code></pre><p>Returns a tuple, with keys matching <code>collect_data</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/danielward27/SyntheticLikelihood.jl/blob/23cf97b906e407dda2f21d957935669d4f1d4572/src/samplers.jl#L110-L118">source</a></section></article><p>Below is an example to sample from a multivariate normal density using the discretized ULA diffusion (Unadjusted ULA Algorithm). In the below example a summary function is not used (it is left to defualt to the identity), so inference is performed on the raw simulator output.</p><pre><code class="language-">using SyntheticLikelihood, Distributions, Plots

# Sample from MVN
d = MvNormal([10 5; 5 10])
function obj_grad_hess(θ)
    ObjGradHess(objective = -logpdf(d, θ),
                       gradient = -gradlogpdf(d, θ))
end

init_θ = [-15., -15]
n_steps = 1000

ULA = ULA(1., obj_grad_hess)
data = run_sampler!(ULA, init_θ, n_steps, [:θ, :counter])

θ_samples = data[:θ]

# Plot samples
x = y = range(-20, 20; length=50)
f(x, y) = -logpdf(d, [x,y])
X = repeat(reshape(x, 1, :), length(y), 1)
Y = repeat(y, 1, length(x))
Z = map(f, X, Y)
p = contour(x, y, f)
scatter!(θ_samples[:,1], θ_samples[:,2], legend = false)</code></pre><p>Note that here a determinisic <code>obj_grad_hess</code> function is used. Generally, in simulation-based-inference this would not be available, and hence this can be replaced for example with <a href="@ref"><code>local_likelihood</code></a>, which uses local regressions to approximate the gradient and Hessian of the likelihood function.</p><h2 id="Implementation-details"><a class="docs-heading-anchor" href="#Implementation-details">Implementation details</a><a id="Implementation-details-1"></a><a class="docs-heading-anchor-permalink" href="#Implementation-details" title="Permalink"></a></h2><p>To implement a new sampler, each sampler must:</p><ul><li>Be a subtype of <code>AbstractSampler</code>.</li><li>Have fields containing the hyperparameters.</li><li>Have an <code>update!</code> method, taking the sampler the <code>LocalApproximation</code> and the <code>SamplerState</code> object as arguments e.g. <code>update!(sampler::MySampler, local_approximation::LocalApproximation, state::SamplerState)</code>. This updates the state (parameters, gradients objective function value etc, and sampler object if applicable).</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../local_regression/">« Local regression</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 17 April 2021 17:19">Saturday 17 April 2021</span>. Using Julia version 1.6.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
