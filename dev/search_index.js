var documenterSearchIndex = {"docs":
[{"location":"simulation_interface/#Simulation-interface","page":"Simulation interface","title":"Simulation interface","text":"","category":"section"},{"location":"simulation_interface/","page":"Simulation interface","title":"Simulation interface","text":"This section describes the structure a simulator should have to work with the package. Simulator functions should take a single positional argument which is a vector of parameters. Summary functions should take the output from the simulator directly as a single positional argument. The summary function defualts to the identity function, meaning the output of of the simulator is used directly.","category":"page"},{"location":"simulation_interface/","page":"Simulation interface","title":"Simulation interface","text":"The primary function for carrying out simulations is simulate_n_s, which simulates n sets of summary statistics (or the raw simulator output if no summary is specified).","category":"page"},{"location":"simulation_interface/","page":"Simulation interface","title":"Simulation interface","text":"simulate_n_s","category":"page"},{"location":"simulation_interface/#SyntheticLikelihood.simulate_n_s","page":"Simulation interface","title":"SyntheticLikelihood.simulate_n_s","text":"Simulates summary statistics from the model under a fixed parameter vector. n_sim is specified as the number of simulations. Simulations can be run on multiple threads using parallel = false. By defualt no summary statistic function is used (by passing the identity function).\n\nsimulate_n_s(θ; simulator, summary, n_sim, parallel)\n\n\nArguments\n\nθ::AbstractVector Parameter vector passed to simulator.\nsimulator::Function Simulator.\nsummary::Function Summary function that takes output of simulator (defualt identity).\nn_sim::Integer Number of simulations.\nparallel::Bool = false Whether to run on multiple threads.\n\n\n\n\n\nAs for above, but a Matrix of parameter values are used, carrying out one     simulation from each row of θ (and hence n_sim is not required).\n\nsimulate_n_s(θ; simulator, summary, parallel)\n\n\n\n\n\n\n","category":"function"},{"location":"local_regression/#Local-regression","page":"Local regression","title":"Local regression","text":"","category":"section"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"Local regressions can be used to estimate the gradient and hessian of the likelihood using local_synthetic_likelihood.","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"Below is an example, inferring the means of a 10 dimensional multivariate normal distribution (with constant covariance), using a single observed sample from the distribution.","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"using SyntheticLikelihood, Distributions, Plots\n\n# Define the simulator\nfunction simulator(θ::Vector{Float64})\n  @assert length(θ) == 10\n  d = MvNormal(θ, sqrt(0.1))\n  rand(d)\nend\n\n# Generate pseudo-observed data\nθ_true = zeros(10)\ns_true = simulator(θ_true)\n","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"We can then define how to sample from the distribution. Below I will use the PreconditionedLangevin sampler with a step size of 0.1, and use local_synthetic_likelihood to estimate the gradient and Hessian of the likelihood. The hyperparameters to be used with local_synthetic_likelihood are passed as key word arguments to the sampler:","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"P = MvNormal(fill(0.5, 10))  # Local area in parameter space\nn_sim = 1000  # Simulations used at each iteration\nθ_orig = convert(Vector{Float64}, -5:5)  # Starting parameter values.\n\npl = PreconditionedLangevin(\n  0.1, local_synthetic_likelihood; s_true, simulator, P, n_sim\n  )","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"Now we can cary out the sampling and plot the results.","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"data = run_sampler!(pl, θ_orig, 1000)\n\n# Plot the samples\nparam_names = reshape([\"θ$i\" for i in 1:10], (1,10))\nplot(data.θ, label = param_names)","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"Plotting the marginals after removing the burn in period:","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"histogram(data.θ[250:end, :], label = param_names, layout = (2,5), size = (800, 600))","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"We can see the samples are generally centered around the true parameter values (all zeros). More specifically, they are centered around s_true in this case, which are generally around zero.","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"local_synthetic_likelihood","category":"page"},{"location":"local_regression/#SyntheticLikelihood.local_synthetic_likelihood","page":"Local regression","title":"SyntheticLikelihood.local_synthetic_likelihood","text":"Estimate negative log-synthetic likelihood, and its gradient and hessian.\n\nlocal_synthetic_likelihood(θ; s_true, simulator, summary, P, n_sim, eigval_threshold)\n\n\nArguments\n\nθ Starting parameter values.\nP::Sampleable Distribution used to peturb parameter value   (e.g. 0 mean multivariate normal).\ns_true The observed summary statistics.\nsimulator The simulator function taking parameter vector θ.\nsummary The summary function taking output from the simulator.\nn_sim The number of peturbed points to use for the local regression.\neigval_threshold Minimum eigenvalue threshold for the estimated hessian.\n\n\n\n\n\n","category":"function"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = SyntheticLikelihood","category":"page"},{"location":"#SyntheticLikelihood","page":"Home","title":"SyntheticLikelihood","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for SyntheticLikelihood package. The package is currently a work in progress.","category":"page"},{"location":"samplers/#Samplers","page":"Samplers","title":"Samplers","text":"","category":"section"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"To sample from a distribution, first a sampler object should be created. The currently available samplers are shown below:","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"Langevin\nPreconditionedLangevin","category":"page"},{"location":"samplers/#SyntheticLikelihood.Langevin","page":"Samplers","title":"SyntheticLikelihood.Langevin","text":"Sampler object for Langevin diffusion. Uses a discrete time Euler approximation of the Langevin diffusion (unadjusted Langevin algorithm), given by the update θ := θ - η/2 * ∇ + ξ, where ξ is given by N(0, ηI).\n\nstep_size\nlocal_approximation\nStep size parameter.\nkwargs\nMust return LocalApproximation object with objective and gradient fields.\n\n\n\n\n\n","category":"type"},{"location":"samplers/#SyntheticLikelihood.PreconditionedLangevin","page":"Samplers","title":"SyntheticLikelihood.PreconditionedLangevin","text":"Sampler object for Preconditioned Langevin diffusion. Also can be thought of as     a stochastic newton method. Uses the update:     θ := θ - η/2 * H⁻¹*∇ + ξ, where ξ ∼ N(0, ηH⁻¹).\n\nstep_size\nlocal_approximation\nStep size parameter\nkwargs\nMust return LocalApproximation object with objective, gradient and hessian.\n\n\n\n\n\n","category":"type"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"The sampler object defines the hyperparameters of the sampler, and a function local_approximation, which takes θ and returns a LocalApproximation object, with fields objective, gradient and hessian. The gradient and hessian defualt to nothing if not required. This approach seems a bit convoluted (compared to e.g. seperately passing objective, gradient and Hessian functions), but it facilitates reusing calculations shared between calculating the objective, gradient and hessian, if desired. The aim should be to explore around the minima of the function, so the objective could be the negative log-posterior, for example.","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"The sampler object can then passed to run_sampler!, to sample from the distribution:","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"run_sampler!","category":"page"},{"location":"samplers/#SyntheticLikelihood.run_sampler!","page":"Samplers","title":"SyntheticLikelihood.run_sampler!","text":"Run the sampling algorithm. Data to collect at each iteration is specified by collect_data, and should be a subset of [:θ, :objective, :gradient, :hessian, :counter].\n\nrun_sampler!(sampler, init_θ, n_steps)\nrun_sampler!(sampler, init_θ, n_steps, collect_data)\n\n\nReturns a tuple, with keys matching collect_data.\n\n\n\n\n\n","category":"function"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"Below is an example to sample from a multivariate normal density using the discretized langevin diffusion (Unadjusted Langevin Algorithm).","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"using SyntheticLikelihood, Distributions, Plots\n\n# Sample from MVN\nd = MvNormal([10 5; 5 10])\nfunction local_approximation(θ)\n    LocalApproximation(objective = -logpdf(d, θ),\n                       gradient = -gradlogpdf(d, θ))\nend\n\ninit_θ = [-15., -15]\nn_steps = 1000\n\nlangevin = Langevin(1., local_approximation)\ndata = run_sampler!(langevin, init_θ, n_steps, [:θ, :counter])\n\nθ_samples = data[:θ]\n\n# Plot samples\nx = y = range(-20, 20; length=50)\nf(x, y) = -logpdf(d, [x,y])\nX = repeat(reshape(x, 1, :), length(y), 1)\nY = repeat(y, 1, length(x))\nZ = map(f, X, Y)\np = contour(x, y, f)\nscatter!(θ_samples[:,1], θ_samples[:,2], legend = false)","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"Note that here a determinisic local_approximation function is used. Generally, in simulation-based-inference this would not be available, and hence this can be replaced for example with local_synthetic_likelihood, which uses local regressions to approximate the gradient and Hessian of the likelihood function.","category":"page"},{"location":"samplers/#Implementation-details","page":"Samplers","title":"Implementation details","text":"","category":"section"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"To implement a new sampler, each sampler must:","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"Be a subtype of AbstractSampler.\nHave fields local_approximation and kwargs (that are passed to local_approximation).\nHave a get_init_state method, which returns a SamplerState object given init_θ e.g. with signature get_init_state(sampler::MySampler, init_θ::Vector{Float64}).\nHave an update! method, taking the sampler and the SamplerState object, e.g. update!(sampler::MySampler, state::SamplerState). This updates the state (parameters, gradients objective function value etc, and sampler object if applicable).","category":"page"}]
}
