var documenterSearchIndex = {"docs":
[{"location":"simulation_interface/#Simulation-interface","page":"Simulation interface","title":"Simulation interface","text":"","category":"section"},{"location":"simulation_interface/","page":"Simulation interface","title":"Simulation interface","text":"This section describes the structure a simulator should have to work with the package. Simulator functions should take a single positional argument which is a vector of parameters. Summary functions should take the output from the simulator directly as a single positional argument. The summary function defualts to the identity function, meaning the output of of the simulator is used directly.","category":"page"},{"location":"simulation_interface/","page":"Simulation interface","title":"Simulation interface","text":"The primary function for carrying out simulations is simulate_n_s, which simulates n sets of summary statistics (or the raw simulator output if no summary is specified).","category":"page"},{"location":"simulation_interface/","page":"Simulation interface","title":"Simulation interface","text":"simulate_n_s","category":"page"},{"location":"simulation_interface/#SyntheticLikelihood.simulate_n_s","page":"Simulation interface","title":"SyntheticLikelihood.simulate_n_s","text":"Simulates summary statistics from the model under a fixed parameter vector. n_sim is specified as the number of simulations. Simulations can be run on multiple threads using parallel = false. By defualt no summary statistic function is used (by passing the identity function).\n\nsimulate_n_s(θ; simulator, summary, n_sim, parallel)\n\n\nArguments\n\nθ::AbstractVector Parameter vector passed to simulator.\nsimulator::Function Simulator.\nsummary::Function Summary function that takes output of simulator (defualt identity).\nn_sim::Integer Number of simulations.\nparallel::Bool = false Whether to run on multiple threads.\n\n\n\n\n\nAs for above, but a Matrix of parameter values are used, carrying out one     simulation from each row of θ (and hence n_sim is not required).\n\nsimulate_n_s(θ; simulator, summary, parallel)\n\n\n\n\n\n\n","category":"function"},{"location":"local_regression/#Local-regression","page":"Local regression","title":"Local regression","text":"","category":"section"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"Local regressions can be used to estimate the gradient and hessian of the likelihood using LocalLikelihood.","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"Below is a basic example, in which we infer the mean of a 10 dimensional multivariate normal distribution, using simulations from the distribution.","category":"page"},{"location":"local_regression/#Define-the-simulator","page":"Local regression","title":"Define the simulator","text":"","category":"section"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"The simulator must take a single positional argument, which is the parameter vector:","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"using SyntheticLikelihood, Distributions, Plots\n\n# Define the simulator\nfunction simulator(θ::Vector{Float64})\n  @assert length(θ) == 10\n  d = MvNormal(θ, sqrt(0.1))\n  rand(d)\nend","category":"page"},{"location":"local_regression/#Ground-truth","page":"Local regression","title":"Ground truth","text":"","category":"section"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"The \"true\" parameters which we will aim to estimate, is just a vector of zeros. We can use this to generate a pseudo-observed data set s_true.","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"θ_true = zeros(10)\ns_true = simulator(θ_true)","category":"page"},{"location":"local_regression/#Defining-how-to-estimate-the-likelihood","page":"Local regression","title":"Defining how to estimate the likelihood","text":"","category":"section"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"We can then define the hyperparameters for estimating the likelihood using local regression using LocalLikelihood.","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"local_likelihood = LocalLikelihood(;\n  simulator, s_true,\n  P = MvNormal(fill(0.5, 10)),\n  n_sim = 1000\n)","category":"page"},{"location":"local_regression/#Defining-sampling-method","page":"Local regression","title":"Defining sampling method","text":"","category":"section"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"We can then define how to sample from the distribution. Below I will use the PreconditionedLangevin sampler with a step size of 0.1.","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"plangevin = PreconditionedLangevin(0.1)","category":"page"},{"location":"local_regression/#Sampling","page":"Local regression","title":"Sampling","text":"","category":"section"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"We can now define some initial parameter values, init_θ, and sample from the distribution:","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"init_θ = convert(Vector{Float64}, 1:10)\ndata = run_sampler!(plangevin, local_likelihood; init_θ, n_steps = 500)","category":"page"},{"location":"local_regression/#Plot-the-samples","page":"Local regression","title":"Plot the samples","text":"","category":"section"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"param_names = reshape([\"θ$i\" for i in 1:10], (1,10))\nplot(data.θ, label = param_names)","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"We can see that after the burn in period, samples are generally centered around the true parameter values (all zeros). More specifically, they are centered around s_true in this case, which are generally around zero.","category":"page"},{"location":"local_regression/#Bayesian-inference","page":"Local regression","title":"Bayesian inference","text":"","category":"section"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"Given a prior, it is also simple to sample from the posterior instead of the likelihood. The prior should be specified using the distributions from Distributions.jl. A multivariate distribution can be used, or alternatively the prior can be formed from independent \"marginal\" priors using a Product distribution from Distributions.jl. For this example the prior is a multivariate normal centered around 5, with no correlation structure, and σ=0.5:","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"prior = MvNormal(fill(5, 10), 0.5)","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"We can then define our objective using LocalPosterior and run the sampler again:","category":"page"},{"location":"local_regression/","page":"Local regression","title":"Local regression","text":"local_posterior = LocalPosterior(local_likelihood, prior)\ndata = run_sampler!(plangevin, local_posterior; init_θ, n_steps = 500)\nplot(data.θ, label = param_names)","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = SyntheticLikelihood","category":"page"},{"location":"#SyntheticLikelihood","page":"Home","title":"SyntheticLikelihood","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for SyntheticLikelihood package. The package is currently a work in progress.","category":"page"},{"location":"samplers/#Samplers","page":"Samplers","title":"Samplers","text":"","category":"section"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"To sample from a distribution, first a sampler object should be created. The currently available samplers are shown below:","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"Langevin\nPreconditionedLangevin","category":"page"},{"location":"samplers/#SyntheticLikelihood.Langevin","page":"Samplers","title":"SyntheticLikelihood.Langevin","text":"Sampler object for Langevin diffusion. Uses a discrete time Euler approximation of the Langevin diffusion (unadjusted Langevin algorithm), given by the update θ := θ - η/2 * ∇ + ξ, where ξ is given by N(0, ηI).\n\nstep_size\nStep size parameter.\n\n\n\n\n\n","category":"type"},{"location":"samplers/#SyntheticLikelihood.PreconditionedLangevin","page":"Samplers","title":"SyntheticLikelihood.PreconditionedLangevin","text":"Sampler object for Preconditioned Langevin diffusion. Also can be thought of as     a stochastic newton method with constant step size. Uses the update:     θ := θ - η/2 * H⁻¹*∇ + ξ, where ξ ∼ N(0, ηH⁻¹).\n\nstep_size\nStep size\n\n\n\n\n\n","category":"type"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"The sampler object defines the hyperparameters of the sampler, and a function obj_grad_hess, which takes θ and returns a ObjGradHess object, with fields objective, gradient and hessian. The gradient and hessian defualt to nothing if not required. This approach seems a bit convoluted (compared to e.g. seperately passing objective, gradient and Hessian functions), but it facilitates reusing calculations shared between calculating the objective, gradient and hessian, if desired. The aim should be to explore around the minima of the function, so the objective could be the negative log-posterior, for example.","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"The sampler object can then passed to run_sampler!, to sample from the distribution:","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"run_sampler!","category":"page"},{"location":"samplers/#SyntheticLikelihood.run_sampler!","page":"Samplers","title":"SyntheticLikelihood.run_sampler!","text":"Run the sampling algorithm. Data to collect at each iteration is specified by collect_data, and should be a subset of [:θ, :objective, :gradient, :hessian, :counter].\n\nrun_sampler!(sampler, local_approximation; init_θ, n_steps, collect_data)\n\n\nReturns a tuple, with keys matching collect_data.\n\n\n\n\n\n","category":"function"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"Below is an example to sample from a multivariate normal density using the discretized langevin diffusion (Unadjusted Langevin Algorithm). In the below example a summary function is not used (it is left to defualt to the identity), so inference is performed on the raw simulator output.","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"using SyntheticLikelihood, Distributions, Plots\n\n# Sample from MVN\nd = MvNormal([10 5; 5 10])\nfunction obj_grad_hess(θ)\n    ObjGradHess(objective = -logpdf(d, θ),\n                       gradient = -gradlogpdf(d, θ))\nend\n\ninit_θ = [-15., -15]\nn_steps = 1000\n\nlangevin = Langevin(1., obj_grad_hess)\ndata = run_sampler!(langevin, init_θ, n_steps, [:θ, :counter])\n\nθ_samples = data[:θ]\n\n# Plot samples\nx = y = range(-20, 20; length=50)\nf(x, y) = -logpdf(d, [x,y])\nX = repeat(reshape(x, 1, :), length(y), 1)\nY = repeat(y, 1, length(x))\nZ = map(f, X, Y)\np = contour(x, y, f)\nscatter!(θ_samples[:,1], θ_samples[:,2], legend = false)","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"Note that here a determinisic obj_grad_hess function is used. Generally, in simulation-based-inference this would not be available, and hence this can be replaced for example with local_likelihood, which uses local regressions to approximate the gradient and Hessian of the likelihood function.","category":"page"},{"location":"samplers/#Implementation-details","page":"Samplers","title":"Implementation details","text":"","category":"section"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"To implement a new sampler, each sampler must:","category":"page"},{"location":"samplers/","page":"Samplers","title":"Samplers","text":"Be a subtype of AbstractSampler.\nHave fields obj_grad_hess and kwargs (that are passed to obj_grad_hess).\nHave a get_init_state method, which returns a SamplerState object given init_θ e.g. with signature get_init_state(sampler::MySampler, init_θ::Vector{Float64}).\nHave an update! method, taking the sampler and the SamplerState object, e.g. update!(sampler::MySampler, state::SamplerState). This updates the state (parameters, gradients objective function value etc, and sampler object if applicable).","category":"page"}]
}
